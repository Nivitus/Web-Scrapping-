{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--\n",
      "\n",
      "           .d88888b.             \n",
      "         .8P\"     \"9bd888b.      \n",
      "        .8P     .d8P\"   `\"988.   \n",
      "     .8888   .d8P\"    ,     98.  \n",
      "   .8P\" 88   8\"    .d98b.    88  \n",
      "  .8P   88   8 .d8P\"   \"98b. 88  \n",
      "  88    88   8P\"  `\"8b.    \"98.  \n",
      "  88.   88   8       8\"8b.    88 \n",
      "   88    \"98.8       8   88   \"88\n",
      "    `8b.    \"98.,  .d8   88    88\n",
      "    88 \"98b.   .d8P\" 8   88   d8\"\n",
      "    88    \"98bP\"    .8   88 .d8\" \n",
      "    \"8b     `    .d8P\"   8888\"   \n",
      "     \"88b.,   .d8P\"     d8\"      \n",
      "       \"9888P98b.     .d8\"       \n",
      "               \"988888P\"         \n",
      "\n",
      "  We're hiring!\n",
      "  openai.com/jobs\n",
      "\n",
      "-->\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=UA-71156606-1\">\n",
      "  </script>\n",
      "  <script>\n",
      "   window.dataLayer = window.dataLayer || [];\n",
      "    function gtag(){dataLayer.push(arguments);}\n",
      "    gtag('js', new Date());\n",
      "\n",
      "    gtag('config', 'UA-71156606-1');\n",
      "  </script>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <title>\n",
      "   Projects\n",
      "  </title>\n",
      "  <meta content=\"width=device-width, initial-scale=1, maximum-scale=1\" name=\"viewport\"/>\n",
      "  <link href=\"/assets/styles/all.css?v=d848b1fb32\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <style>\n",
      "   .js-rotate > *:not(:first-child) {\n",
      "  display: none;\n",
      "}\n",
      "  </style>\n",
      "  <script type=\"text/javascript\">\n",
      "   document.documentElement.className = 'js';\n",
      "  </script>\n",
      "  <link href=\"/assets/images/favicon.svg?v=d848b1fb32\" rel=\"icon\" type=\"image/svg+xml\"/>\n",
      "  <link color=\"#000000\" href=\"/assets/images/mask-icon.svg?v=d848b1fb32\" rel=\"mask-icon\"/>\n",
      "  <link href=\"/favicon.png\" rel=\"icon\" type=\"image/png\"/>\n",
      "  <link href=\"https://openai.com/projects/\" rel=\"canonical\"/>\n",
      "  <meta content=\"no-referrer-when-downgrade\" name=\"referrer\"/>\n",
      "  <meta content=\"OpenAI\" property=\"og:site_name\"/>\n",
      "  <meta content=\"website\" property=\"og:type\"/>\n",
      "  <meta content=\"Projects\" property=\"og:title\"/>\n",
      "  <meta content=\"OpenAI is an AI research and deployment company. Our mission is to ensure that artificial general intelligence benefits all of humanity.\" property=\"og:description\"/>\n",
      "  <meta content=\"https://openai.com/projects/\" property=\"og:url\"/>\n",
      "  <meta content=\"2020-09-01T23:38:44.000Z\" property=\"article:modified_time\"/>\n",
      "  <meta content=\"https://www.facebook.com/openai.research\" property=\"article:publisher\"/>\n",
      "  <meta content=\"summary\" name=\"twitter:card\"/>\n",
      "  <meta content=\"Projects\" name=\"twitter:title\"/>\n",
      "  <meta content=\"OpenAI is an AI research and deployment company. Our mission is to ensure that artificial general intelligence benefits all of humanity.\" name=\"twitter:description\"/>\n",
      "  <meta content=\"https://openai.com/projects/\" name=\"twitter:url\"/>\n",
      "  <meta content=\"Written by\" name=\"twitter:label1\"/>\n",
      "  <meta content=\"OpenAI\" name=\"twitter:data1\"/>\n",
      "  <meta content=\"@openai\" name=\"twitter:site\"/>\n",
      "  <script type=\"application/ld+json\">\n",
      "   {\n",
      "    \"@context\": \"https://schema.org\",\n",
      "    \"@type\": \"Article\",\n",
      "    \"publisher\": {\n",
      "        \"@type\": \"Organization\",\n",
      "        \"name\": \"OpenAI\",\n",
      "        \"url\": \"https://openai.com/\",\n",
      "        \"logo\": {\n",
      "            \"@type\": \"ImageObject\",\n",
      "            \"url\": \"https://openai.com/content/images/2019/05/openai-avatar.png\",\n",
      "            \"width\": 60,\n",
      "            \"height\": 60\n",
      "        }\n",
      "    },\n",
      "    \"author\": {\n",
      "        \"@type\": \"Person\",\n",
      "        \"name\": \"OpenAI\",\n",
      "        \"sameAs\": []\n",
      "    },\n",
      "    \"headline\": \"Projects\",\n",
      "    \"url\": \"https://openai.com/projects/\",\n",
      "    \"dateModified\": \"2020-09-01T23:38:44.000Z\",\n",
      "    \"mainEntityOfPage\": {\n",
      "        \"@type\": \"WebPage\",\n",
      "        \"@id\": \"https://openai.com/\"\n",
      "    }\n",
      "}\n",
      "  </script>\n",
      "  <script defer=\"\" src=\"/public/members.min.js?v=d848b1fb32\">\n",
      "  </script>\n",
      "  <meta content=\"Ghost 3.33\" name=\"generator\"/>\n",
      "  <link href=\"\" rel=\"alternate\" title=\"OpenAI\" type=\"application/rss+xml\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <header>\n",
      "   <nav class=\"nav container\" data-url=\"/projects/\">\n",
      "    <div class=\"row py-10/12\">\n",
      "     <div class=\"col-6 col-sm\">\n",
      "      <a class=\"nav-wordmark d-block\" href=\"/\">\n",
      "       <svg id=\"openai-wordmark\" viewbox=\"0 0 680 180\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "        <path d=\"M410.22,41.09c-13.75,0-23.57,4.7-28.39,13.59l-2.59,4.79V43.41h-22.4v97.85H380.4V83.05c0-13.91,7.55-21.89,20.73-21.89,12.56,0,19.76,7.76,19.76,21.31v58.79h23.56v-63C444.45,55,431.65,41.09,410.22,41.09ZM296,41.09c-27.79,0-45.06,17.33-45.06,45.25v13.74c0,26.83,17.42,43.51,45.45,43.51,18.74,0,31.88-6.88,40.15-21l-14.61-8.39c-6.11,8.15-15.86,13.19-25.54,13.19-14.19,0-22.67-8.76-22.67-23.44v-3.89h65.79V83.82c0-26-17.08-42.73-43.51-42.73Zm22.08,43.14H273.72V81.89c0-16.12,7.91-25,22.28-25,13.83,0,22.08,8.76,22.08,23.44ZM678.32,27.3V8.58H596.87V27.3h28.56v95.25H596.87v18.71h81.45V122.55H649.76V27.3ZM60.67,5.87c-36.39,0-59,22.68-59,59.18V84.79c0,36.51,22.6,59.18,59,59.18s59-22.67,59-59.18V65.05C119.66,28.55,97.05,5.87,60.67,5.87ZM95.33,86.14c0,24.24-12.63,38.15-34.66,38.15S26,110.38,26,86.14V63.7c0-24.24,12.63-38.15,34.66-38.15S95.32,39.46,95.32,63.7Zm98.31-45c-12.36,0-23.07,5.11-28.64,13.69l-2.54,3.9V43.41H140.07V174.93h23.55V127.3l2.53,3.74c5.3,7.85,15.65,12.55,27.68,12.55,20.31,0,40.8-13.28,40.8-42.93V84c0-21.35-12.63-42.91-41-42.91Zm17.44,58.4c0,15.77-9.2,25.57-24,25.57-13.8,0-23.44-10.35-23.44-25.18V85.23c0-15.06,9.72-25.57,23.63-25.57,14.7,0,23.83,9.8,23.83,25.57ZM509.55,8.63,462,141.26h23.9l9.1-28.44h54.65l.09.28,9,28.16h23.93L535.08,8.58Zm-8.67,85.52L522.32,27l21.23,67.07Z\">\n",
      "        </path>\n",
      "       </svg>\n",
      "      </a>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-sm-7 col-md-6 col-lg-5 col-xl-4\">\n",
      "      <ul class=\"d-flex flex-column flex-sm-row justify-content-end justify-content-sm-between small-caps mt-n0.125 mt-sm-0\">\n",
      "       <li class=\"mb-1/6 mb-sm-0\">\n",
      "        <a class=\"nav-link\" data-slug=\"api\" href=\"/api/\">\n",
      "         API\n",
      "        </a>\n",
      "       </li>\n",
      "       <li class=\"mb-1/6 mb-sm-0\">\n",
      "        <a class=\"nav-link active\" data-slug=\"projects\" href=\"/projects/\">\n",
      "         Projects\n",
      "        </a>\n",
      "       </li>\n",
      "       <li class=\"mb-1/6 mb-sm-0\">\n",
      "        <a class=\"nav-link\" data-slug=\"blog\" href=\"/blog/\">\n",
      "         Blog\n",
      "        </a>\n",
      "       </li>\n",
      "       <li class=\"mb-sm-0\">\n",
      "        <a class=\"nav-link\" data-slug=\"about\" href=\"/about/\">\n",
      "         About\n",
      "        </a>\n",
      "       </li>\n",
      "      </ul>\n",
      "     </div>\n",
      "    </div>\n",
      "   </nav>\n",
      "  </header>\n",
      "  <article class=\"post\" id=\"post-projects\">\n",
      "   <div class=\"container mt-3 medium-xsmall-copy\">\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-1 order-md-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"https://arxiv.org/abs/2005.14165\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1\" data-src=\"https://cdn.openai.com/research-covers/gpt-3/gradient.svg\">\n",
      "          <div class=\"mx-auto w-7/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/gpt-3/cover.svg\" src=\"https://cdn.openai.com/research-covers/gpt-3/cover.svg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         GPT-3\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve trained an autoregressive language model with 175 billion parameters.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-external right\" href=\"https://arxiv.org/abs/2005.14165\">\n",
      "        Read paper\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0 order-md-1\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/image-gpt/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/image-gpt/gradient.svg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <video autoplay=\"\" class=\"position-absolute trbl-0 js-lazy\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://cdn.openai.com/research-covers/image-gpt/2x-no-mark-animated-poster.jpg\">\n",
      "             <source data-src=\"https://cdn.openai.com/research-covers/image-gpt/2x-no-mark-animated.mp4\" src=\"https://cdn.openai.com/research-covers/image-gpt/2x-no-mark-animated.mp4\"/>\n",
      "             <img alt=\"\" class=\"position-absolute trbl-0\" data-src=\"https://cdn.openai.com/research-covers/image-gpt/2x-no-mark-animated-poster.jpg\" src=\"https://cdn.openai.com/research-covers/image-gpt/2x-no-mark-animated-poster.jpg\"/>\n",
      "            </video>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Image GPT\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image completions and samples.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/image-gpt/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/image-gpt#completions\">\n",
      "        View samples\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-3\">\n",
      "      <a class=\"d-block fade-parent\" href=\"https://microscope.openai.com/models\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:58.333333333%\">\n",
      "         <video autoplay=\"\" class=\"position-absolute trbl-0 js-lazy\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://cdn.openai.com/microscope/microscope-video-poster.jpg\">\n",
      "          <source data-src=\"https://cdn.openai.com/microscope/microscope-header-web-medium-bitrate.mp4\" src=\"https://cdn.openai.com/microscope/microscope-header-web-medium-bitrate.mp4\"/>\n",
      "          <img alt=\"\" class=\"position-absolute trbl-0\" data-src=\"https://cdn.openai.com/microscope/microscope-video-poster.jpg\" src=\"https://cdn.openai.com/microscope/microscope-video-poster.jpg\"/>\n",
      "         </video>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Microscope\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         Visualizations of significant layers and neurons of vision models.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-external right\" href=\"https://microscope.openai.com/models\">\n",
      "        Visit\n",
      "       </a>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/microscope/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/jukebox/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/jukebox/gradient.svg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/jukebox/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/jukebox/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Jukebox\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/jukebox/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "       <a class=\"fade icon-external right\" href=\"https://jukebox.openai.com\">\n",
      "        Explore samples\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/tags/gpt-2/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:56.25%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://openai.com/content/images/2019/08/gpt-2_update_8-14a-40.jpg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         GPT-2\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         A large-scale unsupervised language model which generates text and performs rudimentary reading comprehension, machine translation, question answering, and summarization.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/tags/gpt-2/\">\n",
      "        View collection\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/solving-rubiks-cube/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:56.25%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/solving-rubiks-cube/images/project-cover.jpg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Solving Rubik’s Cube with a Robot Hand\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve trained a pair of neural networks to solve the Rubik’s Cube with a human-like robot hand.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/solving-rubiks-cube/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "       <a class=\"fade icon-play right\" href=\"/blog/solving-rubiks-cube#video\">\n",
      "        Watch video\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/safety-gym/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:58.333333333%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://openai.com/content/images/size/w1400/2019/11/safety-gym-cover.png\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Safety Gym\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         Environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while training.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/safety-gym/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-3\">\n",
      "      <a class=\"d-block fade-parent\" href=\"https://spinningup.openai.com\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:60%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://openai.com/content/images/size/w1400/2018/11/spinningup.jpg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Spinning Up in Deep RL\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         An educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-external right\" href=\"https://spinningup.openai.com\">\n",
      "        Visit\n",
      "       </a>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/spinning-up-in-deep-rl/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/emergent-tool-use/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:56.25%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/emergent-tool-use/images/poster-20190916b-noscrim.jpg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Emergent Tool Use from Multi-Agent Interaction\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/emergent-tool-use/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/five/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"js-rotate mb-0.5\" data-speed=\"1500\">\n",
      "         <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0\" style=\"padding-top:66.666666667%\">\n",
      "          <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/dota-2/images/finals-audience.jpg\">\n",
      "          </div>\n",
      "         </figure>\n",
      "         <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0\" style=\"padding-top:66.666666667%\">\n",
      "          <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/dota-2/images/openai-five-bigscreen.jpg\">\n",
      "          </div>\n",
      "         </figure>\n",
      "         <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0\" style=\"padding-top:66.666666667%\">\n",
      "          <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/dota-2/images/ti7-gameplay.jpg\">\n",
      "          </div>\n",
      "         </figure>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         OpenAI Five\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         AI for the five-on-five video game Dota 2.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/five/\">\n",
      "        View project\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/tags/programs/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:100%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/projects/scholars.png\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         OpenAI Scholars\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We provide stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/tags/programs/\">\n",
      "        View programs\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-1\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/introducing-activation-atlases/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:60%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://openai.com/content/images/size/w1400/2019/03/aa-cover-1.jpg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Activation Atlases\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve created, in collaboration with Google researchers, a new technique for visualizing what interactions between neurons can represent.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/introducing-activation-atlases/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "       <a class=\"fade icon-external right\" href=\"https://distill.pub/2019/activation-atlas/app.html\">\n",
      "        Try demo\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/musenet/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/musenet/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/musenet/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/musenet/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         MuseNet\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/musenet/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/musenet#try\">\n",
      "        Try MuseNet\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/better-language-models/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/better-language-models/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <video autoplay=\"\" class=\"position-absolute trbl-0 js-lazy\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://cdn.openai.com/research-covers/better-language-models/2x-no-mark.jpg\">\n",
      "             <source data-src=\"https://cdn.openai.com/research-covers/better-language-models/2x-no-mark-animated.mp4\" src=\"https://cdn.openai.com/research-covers/better-language-models/2x-no-mark-animated.mp4\"/>\n",
      "             <img alt=\"\" class=\"position-absolute trbl-0\" data-src=\"https://cdn.openai.com/research-covers/better-language-models/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/better-language-models/2x-no-mark.jpg\"/>\n",
      "            </video>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Better Language Models and Their Implications\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/better-language-models/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/better-language-models#samples\">\n",
      "        View samples\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/science-of-ai/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/science-of-ai/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/science-of-ai/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/science-of-ai/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         How AI Training Scales\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/science-of-ai/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-1 order-md-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/tags/programs/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:100%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/projects/fellows.svg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         OpenAI Fellows\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We offer a compensated 6-month apprenticeship people who want to be an AI researcher, but do not have a formal background in the field.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/tags/programs/\">\n",
      "        View programs\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0 order-md-1\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/learning-dexterity/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:58.333333333%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/learning-dexterity/project-cover.jpg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Learning Dexterity\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve trained a human-like robot hand to manipulate physical objects with unprecedented dexterity.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/learning-dexterity/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-3\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/glow/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:100%\">\n",
      "         <video autoplay=\"\" class=\"position-absolute trbl-0 js-lazy\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"\">\n",
      "          <source data-src=\"https://cdn.openai.com/research-covers/glow/videos/both_loop_new.mp4\" src=\"https://cdn.openai.com/research-covers/glow/videos/both_loop_new.mp4\"/>\n",
      "          <img alt=\"\" class=\"position-absolute trbl-0\" data-src=\"\" src=\"\"/>\n",
      "         </video>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Glow: Better Reversible Generative Models\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We introduce Glow, a reversible generative model which uses invertible 1x1 convolutions.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/glow/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/glow#demo\">\n",
      "        Try demo\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/language-unsupervised/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/language-unsupervised/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/language-unsupervised/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/language-unsupervised/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Improving Language Understanding with Unsupervised Learning\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we’re also releasing.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/language-unsupervised/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/charter/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/openai-charter/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/openai-charter/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/openai-charter/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         OpenAI Charter\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re releasing a charter that describes the principles we use to execute on OpenAI’s mission.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/charter/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/retro-contest/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/retro-contest/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/retro-contest/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/retro-contest/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Retro Contest\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re launching a transfer learning contest that measures a reinforcement learning algorithm’s ability to generalize from previous experience.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/retro-contest/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "       <a class=\"fade icon-external right\" href=\"https://contest.openai.com\">\n",
      "        Visit contest\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/gym-retro/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:56.25%\">\n",
      "         <video autoplay=\"\" class=\"position-absolute trbl-0 js-lazy\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://cdn.openai.com/research-covers/retro-heavy/heavy_tile.png\">\n",
      "          <source data-src=\"https://cdn.openai.com/gym-retro/project-cover.mp4\" src=\"https://cdn.openai.com/gym-retro/project-cover.mp4\"/>\n",
      "          <img alt=\"\" class=\"position-absolute trbl-0\" data-src=\"https://cdn.openai.com/research-covers/retro-heavy/heavy_tile.png\" src=\"https://cdn.openai.com/research-covers/retro-heavy/heavy_tile.png\"/>\n",
      "         </video>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Gym Retro\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re releasing the full version of Gym Retro, a platform for reinforcement learning research on games.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/gym-retro/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-3\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/debate/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:50%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://openai.com/content/images/2018/05/debatedog.gif\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         AI Safety via Debate\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/debate/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "       <a class=\"fade icon-external right\" href=\"https://debate-game.openai.com\">\n",
      "        Play Game\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/ingredients-for-robotics-research/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/ingredients-for-robotics-research/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/ingredients-for-robotics-research/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/ingredients-for-robotics-research/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Ingredients for Robotics Research\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/ingredients-for-robotics-research/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/block-sparse-gpu-kernels/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/block-sparse-gpu-kernels/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <video autoplay=\"\" class=\"position-absolute trbl-0 js-lazy\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"https://cdn.openai.com/research-covers/block-sparse-gpu-kernels/2x-no-mark-animated-poster.jpg\">\n",
      "             <source data-src=\"https://cdn.openai.com/research-covers/block-sparse-gpu-kernels/2x-no-mark-animated.mp4\" src=\"https://cdn.openai.com/research-covers/block-sparse-gpu-kernels/2x-no-mark-animated.mp4\"/>\n",
      "             <img alt=\"\" class=\"position-absolute trbl-0\" data-src=\"https://cdn.openai.com/research-covers/block-sparse-gpu-kernels/2x-no-mark-animated-poster.jpg\" src=\"https://cdn.openai.com/research-covers/block-sparse-gpu-kernels/2x-no-mark-animated-poster.jpg\"/>\n",
      "            </video>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Block-Sparse GPU Kernels\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/block-sparse-gpu-kernels/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/tags/five/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:100%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/projects/openai-five.svg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         OpenAI Five\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         AI for the five-on-five video game Dota 2.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/tags/five/\">\n",
      "        View collection\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-1\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/reptile/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:56.25%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/Reptile/project-cover.png\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Reptile: A Scalable Meta-Learning Algorithm\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/reptile/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/reptile#demo\">\n",
      "        Try demo\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/competitive-self-play/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/competitive-self-play/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/competitive-self-play/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/competitive-self-play/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Competitive Self-Play\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/competitive-self-play/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/baselines-acktr-a2c/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/baselines-acktr-a2c/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/baselines-acktr-a2c/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/baselines-acktr-a2c/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         OpenAI Baselines: ACKTR &amp; A2C\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we’ve found gives equal performance.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/baselines-acktr-a2c/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/better-exploration-with-parameter-noise/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/better-exploration-with-parameter-noise/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/better-exploration-with-parameter-noise/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/better-exploration-with-parameter-noise/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Better Exploration with Parameter Noise\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/better-exploration-with-parameter-noise/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/openai-baselines-ppo/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/openai-baselines-ppo/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/openai-baselines-ppo/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/openai-baselines-ppo/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Proximal Policy Optimization\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/openai-baselines-ppo/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/openai-baselines-dqn/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/openai-baselines-dqn/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/openai-baselines-dqn/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/openai-baselines-dqn/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         OpenAI Baselines: DQN\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/openai-baselines-dqn/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/robots-that-learn/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/robots-that-learn/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/robots-that-learn/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/robots-that-learn/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Robots that Learn\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/robots-that-learn/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/roboschool/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:56.25%\">\n",
      "         <video autoplay=\"\" class=\"position-absolute trbl-0 js-lazy\" loop=\"\" muted=\"\" playsinline=\"\" poster=\"\">\n",
      "          <source data-src=\"https://cdn.openai.com/roboschool/demo-race.mp4\" src=\"https://cdn.openai.com/roboschool/demo-race.mp4\"/>\n",
      "          <img alt=\"\" class=\"position-absolute trbl-0\" data-src=\"\" src=\"\"/>\n",
      "         </video>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Roboschool\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/roboschool/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-3\">\n",
      "      <a class=\"d-block fade-parent\" href=\"https://github.com/openai/baselines\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:100%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/projects/baselines.svg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Baselines\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         High-quality implementations of reinforcement learning algorithms\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-external right\" href=\"https://github.com/openai/baselines\">\n",
      "        View code\n",
      "       </a>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/tags/baselines/\">\n",
      "        View collection\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/unsupervised-sentiment-neuron/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/unsupervised-sentiment-neuron/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/unsupervised-sentiment-neuron/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/unsupervised-sentiment-neuron/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Unsupervised Sentiment Neuron\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/unsupervised-sentiment-neuron/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/evolution-strategies/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/evolution-strategies/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/evolution-strategies/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/evolution-strategies/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Evolution Strategies as a Scalable Alternative to Reinforcement Learning\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’ve discovered that evolution strategies (ES), an optimization technique that’s been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks, while overcoming many of RL’s inconveniences.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/evolution-strategies/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-0\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/universe/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:100%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/projects/universe.svg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Universe\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         We’re releasing Universe, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites and other applications.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/universe/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-6 col-md-3 mb-2 mb-md-2.5 order-1\">\n",
      "      <a class=\"d-block fade-parent\" href=\"https://gym.openai.com/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <figure class=\"position-relative bg-fg-2 rounded-small overflow-hidden inset-border mb-0.5\" style=\"padding-top:100%\">\n",
      "         <div class=\"position-absolute trbl-0 bg-cover js-lazy\" data-src=\"https://cdn.openai.com/projects/gym.svg\">\n",
      "         </div>\n",
      "        </figure>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Gym\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         Toolkit for developing and comparing reinforcement learning algorithms.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-external right\" href=\"https://gym.openai.com/\">\n",
      "        Visit\n",
      "       </a>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/openai-gym-beta/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"col-12 col-md-6 mb-2 mb-md-2.5 order-2\">\n",
      "      <a class=\"d-block fade-parent\" href=\"/blog/generative-models/\">\n",
      "       <div class=\"fade-child-xxheavy transition-opacity d-block\">\n",
      "        <div class=\"bg-fg-2 inset-border rounded-small mb-0.5 overflow-hidden\">\n",
      "         <div class=\"bg-cover js-lazy py-1.5\" data-src=\"https://cdn.openai.com/research-covers/generative-models/gradient.jpg\">\n",
      "          <div class=\"mx-auto w-5/12\">\n",
      "           <figure class=\"bg-fg-2 mb-0 position-relative rounded-small overflow-hidden shadowed-xheavy\" style=\"padding-bottom:132.915360502%\">\n",
      "            <img alt=\"\" class=\"position-absolute trbl-0 js-lazy\" data-src=\"https://cdn.openai.com/research-covers/generative-models/2x-no-mark.jpg\" src=\"https://cdn.openai.com/research-covers/generative-models/2x-no-mark.jpg\"/>\n",
      "           </figure>\n",
      "          </div>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div>\n",
      "        <h5 class=\"mb-0.5 balance-text medium-xsmall-copy fade-child\">\n",
      "         Generative Models\n",
      "        </h5>\n",
      "        <div class=\"color-fg-80 mb-0.5 balance-text\">\n",
      "         This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning.\n",
      "        </div>\n",
      "       </div>\n",
      "      </a>\n",
      "      <div>\n",
      "       <a class=\"fade icon-next right\" href=\"/blog/generative-models/\">\n",
      "        Learn more\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"row\">\n",
      "    </div>\n",
      "   </div>\n",
      "  </article>\n",
      "  <footer class=\"footer container\">\n",
      "   <div class=\"row line-height-1.65 mb-1\">\n",
      "    <div class=\"col-12 col-md-3 col-xl-3\">\n",
      "     <a class=\"d-block footer-logo mb-1.5 position-relative\" href=\"/\" style=\"left:-1px\">\n",
      "      <svg id=\"openai-horizontal\" viewbox=\"0 0 936 232\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "       <path d=\"M667.21,90.58c-13.76,0-23.58,4.7-28.4,13.6L636.22,109V92.9H613.83v97.86h23.55V132.54c0-13.91,7.56-21.89,20.73-21.89,12.56,0,19.76,7.77,19.76,21.31v58.8h23.56v-63C701.43,104.46,688.64,90.58,667.21,90.58ZM553,90.58c-27.79,0-45,17.34-45,45.25v13.74c0,26.84,17.41,43.51,45.44,43.51,18.75,0,31.89-6.87,40.16-21L579,163.68c-6.11,8.15-15.87,13.2-25.55,13.2-14.19,0-22.66-8.76-22.66-23.44v-3.89h65.73V133.32c0-26-17.07-42.74-43.5-42.74Zm22.09,43.15H530.71v-2.35c0-16.11,7.91-25,22.27-25,13.83,0,22.09,8.76,22.09,23.44ZM935.31,76.79V58.07H853.85V76.79h28.56V172H853.85v18.72h81.46V172H906.74V76.79ZM317.65,55.37c-36.38,0-59,22.67-59,59.18v19.74c0,36.5,22.61,59.18,59,59.18s59-22.68,59-59.18V114.55C376.64,78,354,55.37,317.65,55.37Zm34.66,80.27c0,24.24-12.63,38.14-34.66,38.14S283,159.88,283,135.64V113.19c0-24.24,12.64-38.14,34.66-38.14s34.66,13.9,34.66,38.14Zm98.31-45.06c-12.36,0-23.06,5.12-28.64,13.69l-2.53,3.9V92.9h-22.4V224.43h23.56V176.79l2.52,3.74c5.3,7.86,15.65,12.55,27.69,12.55,20.31,0,40.8-13.27,40.8-42.93V133.51c0-21.37-12.63-42.93-41-42.93ZM468.06,149c0,15.77-9.2,25.57-24,25.57-13.8,0-23.43-10.36-23.43-25.18V134.67c0-15,9.71-25.56,23.63-25.56,14.69,0,23.82,9.79,23.82,25.56ZM766.53,58.08,719,190.76h23.93l9.1-28.44h54.64l.09.28,9,28.16h23.92L792.07,58.07Zm-8.66,85.53,21.44-67.08,21.22,67.08Z\">\n",
      "       </path>\n",
      "       <path d=\"M212.59,95.12a57.27,57.27,0,0,0-4.92-47.05,58,58,0,0,0-62.4-27.79A57.29,57.29,0,0,0,102.06,1,57.94,57.94,0,0,0,46.79,41.14,57.31,57.31,0,0,0,8.5,68.93a58,58,0,0,0,7.13,67.94,57.31,57.31,0,0,0,4.92,47A58,58,0,0,0,83,211.72,57.31,57.31,0,0,0,126.16,231a57.94,57.94,0,0,0,55.27-40.14,57.3,57.3,0,0,0,38.28-27.79A57.92,57.92,0,0,0,212.59,95.12ZM126.16,216a42.93,42.93,0,0,1-27.58-10c.34-.19,1-.52,1.38-.77l45.8-26.44a7.43,7.43,0,0,0,3.76-6.51V107.7l19.35,11.17a.67.67,0,0,1,.38.54v53.45A43.14,43.14,0,0,1,126.16,216ZM33.57,176.46a43,43,0,0,1-5.15-28.88c.34.21.94.57,1.36.81l45.81,26.45a7.44,7.44,0,0,0,7.52,0L139,142.52v22.34a.67.67,0,0,1-.27.6L92.43,192.18a43.14,43.14,0,0,1-58.86-15.77Zm-12-100A42.92,42.92,0,0,1,44,57.56V112a7.45,7.45,0,0,0,3.76,6.51l55.9,32.28L84.24,162a.68.68,0,0,1-.65.06L37.3,135.33A43.13,43.13,0,0,1,21.53,76.46Zm159,37-55.9-32.28L144,70a.69.69,0,0,1,.65-.06l46.29,26.73a43.1,43.1,0,0,1-6.66,77.76V120a7.44,7.44,0,0,0-3.74-6.54Zm19.27-29c-.34-.21-.94-.57-1.36-.81L152.67,57.2a7.44,7.44,0,0,0-7.52,0L89.25,89.47V67.14a.73.73,0,0,1,.28-.6l46.29-26.72a43.1,43.1,0,0,1,64,44.65ZM78.7,124.3,59.34,113.13a.73.73,0,0,1-.37-.54V59.14A43.09,43.09,0,0,1,129.64,26c-.34.19-.95.52-1.38.77L82.46,53.21a7.45,7.45,0,0,0-3.76,6.51Zm10.51-22.67,24.9-14.38L139,101.63v28.74L114.1,144.75,89.2,130.37Z\">\n",
      "       </path>\n",
      "      </svg>\n",
      "     </a>\n",
      "    </div>\n",
      "    <div class=\"col-12 col-sm-4 col-md-3 col-xl-3 medium-xsmall-copy mb-1\">\n",
      "     <div>\n",
      "      Company\n",
      "     </div>\n",
      "     <hr class=\"mt-0.1 mb-1/6\"/>\n",
      "     <ul class=\"multicol-2 multicol-sm-1\">\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/api/\">\n",
      "        API\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/projects/\">\n",
      "        Projects\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/blog/\">\n",
      "        Blog\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/about/\">\n",
      "        About\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/jobs/\">\n",
      "        Jobs\n",
      "       </a>\n",
      "      </li>\n",
      "     </ul>\n",
      "    </div>\n",
      "    <div class=\"col-6 col-sm-4 col-md-3 col-xl-3 medium-xsmall-copy mb-1\">\n",
      "     <div>\n",
      "      Latest\n",
      "     </div>\n",
      "     <hr class=\"mt-0.1 mb-1/6\"/>\n",
      "     <ul>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/blog/tags/research/\">\n",
      "        Research\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/blog/tags/announcements/\">\n",
      "        Announcements\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/blog/tags/events/\">\n",
      "        Events\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/blog/tags/milestones/\">\n",
      "        Milestones\n",
      "       </a>\n",
      "      </li>\n",
      "     </ul>\n",
      "    </div>\n",
      "    <div class=\"col-6 col-sm-4 col-md-3 col-xl-3 medium-xsmall-copy mb-1\">\n",
      "     <div>\n",
      "      Resources\n",
      "     </div>\n",
      "     <hr class=\"mt-0.1 mb-1/6\"/>\n",
      "     <ul>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/newsroom/\">\n",
      "        Newsroom\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/brand/\">\n",
      "        Brand Assets\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/papers/\">\n",
      "        Papers\n",
      "       </a>\n",
      "      </li>\n",
      "      <li>\n",
      "       <a class=\"faded\" href=\"/charter/\">\n",
      "        Charter\n",
      "       </a>\n",
      "      </li>\n",
      "     </ul>\n",
      "    </div>\n",
      "   </div>\n",
      "  </footer>\n",
      "  <script src=\"/assets/scripts/main.js?v=d848b1fb32\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script>\n",
      "   var initRotate = function () {\n",
      "  var rotates = document.querySelectorAll('.js-rotate');\n",
      "  if (!rotates.length) return;\n",
      "  // for each set of rotates\n",
      "  rotates.forEach(function (r) {\n",
      "    // move first child to end every n seconds\n",
      "    window.setInterval(function(){\n",
      "      moveToEnd(r, r.firstElementChild);\n",
      "    }, r.dataset.speed);\n",
      "  });\n",
      "};\n",
      "var moveToEnd = function (parent, child) {\n",
      "  parent.removeChild(child);\n",
      "  parent.appendChild(child); // append to parent\n",
      "};\n",
      "\n",
      "// init\n",
      "document.addEventListener('DOMContentLoaded', function () {\n",
      "  initRotate();\n",
      "});\n",
      "  </script>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "soup = BeautifulSoup(requests.get(\"https://openai.com/projects/#papers\").text, 'lxml')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3\n"
     ]
    }
   ],
   "source": [
    "Title = soup.find('h5', class_='mb-0.5 balance-text medium-xsmall-copy fade-child')\n",
    "print(Title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3\n",
      "Image GPT\n",
      "Microscope\n",
      "Jukebox\n",
      "GPT-2\n",
      "Solving Rubik’s Cube with a Robot Hand\n",
      "Safety Gym\n",
      "Spinning Up in Deep RL\n",
      "Emergent Tool Use from Multi-Agent Interaction\n",
      "OpenAI Five\n",
      "OpenAI Scholars\n",
      "Activation Atlases\n",
      "MuseNet\n",
      "Better Language Models and Their Implications\n",
      "How AI Training Scales\n",
      "OpenAI Fellows\n",
      "Learning Dexterity\n",
      "Glow: Better Reversible Generative Models\n",
      "Improving Language Understanding with Unsupervised Learning\n",
      "OpenAI Charter\n",
      "Retro Contest\n",
      "Gym Retro\n",
      "AI Safety via Debate\n",
      "Ingredients for Robotics Research\n",
      "Block-Sparse GPU Kernels\n",
      "OpenAI Five\n",
      "Reptile: A Scalable Meta-Learning Algorithm\n",
      "Competitive Self-Play\n",
      "OpenAI Baselines: ACKTR & A2C\n",
      "Better Exploration with Parameter Noise\n",
      "Proximal Policy Optimization\n",
      "OpenAI Baselines: DQN\n",
      "Robots that Learn\n",
      "Roboschool\n",
      "Baselines\n",
      "Unsupervised Sentiment Neuron\n",
      "Evolution Strategies as a Scalable Alternative to Reinforcement Learning\n",
      "Universe\n",
      "Gym\n",
      "Generative Models\n"
     ]
    }
   ],
   "source": [
    "for aut in soup.find_all('h5', class_='mb-0.5 balance-text medium-xsmall-copy fade-child'):\n",
    "    print(aut.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/2005.14165\n",
      "https://microscope.openai.com/models\n",
      "https://jukebox.openai.com\n",
      "https://spinningup.openai.com\n",
      "https://distill.pub/2019/activation-atlas/app.html\n",
      "https://contest.openai.com\n",
      "https://debate-game.openai.com\n",
      "https://github.com/openai/baselines\n",
      "https://gym.openai.com/\n"
     ]
    }
   ],
   "source": [
    "for paper_link in soup.find_all('a', class_='fade icon-external right'):\n",
    "    print(paper_link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/2005.14165\n"
     ]
    }
   ],
   "source": [
    "Title_lin = soup.find('a', class_='d-block fade-parent')\n",
    "print(Title_lin['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/2005.14165\n",
      "/blog/image-gpt/\n",
      "https://microscope.openai.com/models\n",
      "/blog/jukebox/\n",
      "/blog/tags/gpt-2/\n",
      "/blog/solving-rubiks-cube/\n",
      "/blog/safety-gym/\n",
      "https://spinningup.openai.com\n",
      "/blog/emergent-tool-use/\n",
      "/five/\n",
      "/blog/tags/programs/\n",
      "/blog/introducing-activation-atlases/\n",
      "/blog/musenet/\n",
      "/blog/better-language-models/\n",
      "/blog/science-of-ai/\n",
      "/blog/tags/programs/\n",
      "/blog/learning-dexterity/\n",
      "/blog/glow/\n",
      "/blog/language-unsupervised/\n",
      "/charter/\n",
      "/blog/retro-contest/\n",
      "/blog/gym-retro/\n",
      "/blog/debate/\n",
      "/blog/ingredients-for-robotics-research/\n",
      "/blog/block-sparse-gpu-kernels/\n",
      "/blog/tags/five/\n",
      "/blog/reptile/\n",
      "/blog/competitive-self-play/\n",
      "/blog/baselines-acktr-a2c/\n",
      "/blog/better-exploration-with-parameter-noise/\n",
      "/blog/openai-baselines-ppo/\n",
      "/blog/openai-baselines-dqn/\n",
      "/blog/robots-that-learn/\n",
      "/blog/roboschool/\n",
      "https://github.com/openai/baselines\n",
      "/blog/unsupervised-sentiment-neuron/\n",
      "/blog/evolution-strategies/\n",
      "/blog/universe/\n",
      "https://gym.openai.com/\n",
      "/blog/generative-models/\n"
     ]
    }
   ],
   "source": [
    "for paper_l in soup.find_all('a', class_='d-block fade-parent'):\n",
    "    print(paper_l['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We’ve trained an autoregressive language model with 175 billion parameters.\n",
      "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image completions and samples.\n",
      "Visualizations of significant layers and neurons of vision models.\n",
      "We’re introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles.\n",
      "A large-scale unsupervised language model which generates text and performs rudimentary reading comprehension, machine translation, question answering, and summarization.\n",
      "We’ve trained a pair of neural networks to solve the Rubik’s Cube with a human-like robot hand.\n",
      "Environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while training.\n",
      "An educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning.\n",
      "We’ve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek.\n",
      "AI for the five-on-five video game Dota 2.\n",
      "We provide stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.\n",
      "We’ve created, in collaboration with Google researchers, a new technique for visualizing what interactions between neurons can represent.\n",
      "We’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles.\n",
      "We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization.\n",
      "We’ve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks.\n",
      "We offer a compensated 6-month apprenticeship people who want to be an AI researcher, but do not have a formal background in the field.\n",
      "We’ve trained a human-like robot hand to manipulate physical objects with unprecedented dexterity.\n",
      "We introduce Glow, a reversible generative model which uses invertible 1x1 convolutions.\n",
      "We’ve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we’re also releasing.\n",
      "We’re releasing a charter that describes the principles we use to execute on OpenAI’s mission.\n",
      "We’re launching a transfer learning contest that measures a reinforcement learning algorithm’s ability to generalize from previous experience.\n",
      "We’re releasing the full version of Gym Retro, a platform for reinforcement learning research on games.\n",
      "We’re proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.\n",
      "We’re releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year.\n",
      "We’re releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights.\n",
      "AI for the five-on-five video game Dota 2.\n",
      "We’ve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. \n",
      "We’ve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind.\n",
      "We’re releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we’ve found gives equal performance.\n",
      "We’ve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance.\n",
      "We’re releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune.\n",
      "We’re open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results.\n",
      "We’ve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.\n",
      "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.\n",
      "High-quality implementations of reinforcement learning algorithms\n",
      "We’ve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.\n",
      "We’ve discovered that evolution strategies (ES), an optimization technique that’s been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks, while overcoming many of RL’s inconveniences.\n",
      "We’re releasing Universe, a software platform for measuring and training an AI’s general intelligence across the world’s supply of games, websites and other applications.\n",
      "Toolkit for developing and comparing reinforcement learning algorithms.\n",
      "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning.\n"
     ]
    }
   ],
   "source": [
    "for paper_lp in soup.find_all('div', class_='color-fg-80 mb-0.5 balance-text'):\n",
    "    print(paper_lp.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper_lp in soup.find_all('div', class_='dateline'):\n",
    "    print(paper_lp.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
      "<html lang=\"en\" xml:lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\">\n",
      " <head>\n",
      "  <title>\n",
      "   [2005.14165] Language Models are Few-Shot Learners\n",
      "  </title>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <link href=\"https://static.arxiv.org/static/browse/0.3.2.5/images/icons/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/>\n",
      "  <link href=\"https://static.arxiv.org/static/browse/0.3.2.5/css/arXiv.css?v=20200727\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <link href=\"https://static.arxiv.org/static/browse/0.3.2.5/css/arXiv-print.css?v=20200611\" media=\"print\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <link href=\"https://static.arxiv.org/static/browse/0.3.2.5/css/browse_search.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <script language=\"javascript\" src=\"https://static.arxiv.org/static/browse/0.3.2.5/js/accordion.js\">\n",
      "  </script>\n",
      "  <!-- Pendo -->\n",
      "  <script>\n",
      "   (function(apiKey){\n",
      "      (function(p,e,n,d,o){var v,w,x,y,z;o=p[d]=p[d]||{};o._q=[];\n",
      "      v=['initialize','identify','updateOptions','pageLoad','track'];for(w=0,x=v.length;w<x;++w)(function(m){\n",
      "          o[m]=o[m]||function(){o._q[m===v[0]?'unshift':'push']([m].concat([].slice.call(arguments,0)));};})(v[w]);\n",
      "          y=e.createElement(n);y.async=!0;y.src='https://content.analytics.arxiv.org/agent/static/'+apiKey+'/pendo.js';\n",
      "          z=e.getElementsByTagName(n)[0];z.parentNode.insertBefore(y,z);})(window,document,'script','pendo');\n",
      "\n",
      "          // Call this whenever information about your visitors becomes available\n",
      "          // Please use Strings, Numbers, or Bools for value types.\n",
      "          pendo.initialize({\n",
      "              visitor: {\n",
      "                  id:              'VISITOR-UNIQUE-ID'   // Required if user is logged in\n",
      "                  // email:        // Recommended if using Pendo Feedback, or NPS Email\n",
      "                  // full_name:    // Recommended if using Pendo Feedback\n",
      "                  // role:         // Optional\n",
      "\n",
      "                  // You can add any additional visitor level key-values here,\n",
      "                  // as long as it's not one of the above reserved names.\n",
      "              },\n",
      "\n",
      "              account: {\n",
      "                  id:           'ACCOUNT-UNIQUE-ID' // Highly recommended\n",
      "                  // name:         // Optional\n",
      "                  // is_paying:    // Recommended if using Pendo Feedback\n",
      "                  // monthly_value:// Recommended if using Pendo Feedback\n",
      "                  // planLevel:    // Optional\n",
      "                  // planPrice:    // Optional\n",
      "                  // creationDate: // Optional\n",
      "\n",
      "                  // You can add any additional account level key-values here,\n",
      "                  // as long as it's not one of the above reserved names.\n",
      "              }\n",
      "          });\n",
      "  })('d6494389-b427-4103-7c76-03182ecc8e60');\n",
      "  </script>\n",
      "  <link href=\"/bibex/bibex.css?20181010\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <script src=\"https://static.arxiv.org/static/browse/0.3.2.5/js/mathjaxToggle.min.js\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script src=\"https://arxiv-org.atlassian.net/s/d41d8cd98f00b204e9800998ecf8427e-T/zca7yc/b/13/a44af77267a987a660377e5c46e0fb64/_/download/batch/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector/com.atlassian.jira.collector.plugin.jira-issue-collector-plugin:issuecollector.js?locale=en-US&amp;collectorId=7a8da419\" type=\"text/javascript\">\n",
      "  </script>\n",
      "  <script type=\"text/javascript\">\n",
      "   window.ATL_JQ_PAGE_PROPS =  {\n",
      "  \"triggerFunction\": function(showCollectorDialog) {\n",
      "    //Requires that jQuery is available!\n",
      "    jQuery(\"#feedback-button\").click(function(e) {\n",
      "      e.preventDefault();\n",
      "      showCollectorDialog();\n",
      "    });\n",
      "  },\n",
      "  fieldValues: {\n",
      "    \"components\": [\"15700\"],  // Jira ID for browse component\n",
      "    \"versions\": [\"14251\"],    // Jira ID for browse-0.3.2 release\n",
      "    \"customfield_11401\": window.location.href\n",
      "  }\n",
      "  };\n",
      "  </script>\n",
      "  <meta content=\"Language Models are Few-Shot Learners\" name=\"citation_title\"/>\n",
      "  <meta content=\"Brown, Tom B.\" name=\"citation_author\"/>\n",
      "  <meta content=\"Mann, Benjamin\" name=\"citation_author\"/>\n",
      "  <meta content=\"Ryder, Nick\" name=\"citation_author\"/>\n",
      "  <meta content=\"Subbiah, Melanie\" name=\"citation_author\"/>\n",
      "  <meta content=\"Kaplan, Jared\" name=\"citation_author\"/>\n",
      "  <meta content=\"Dhariwal, Prafulla\" name=\"citation_author\"/>\n",
      "  <meta content=\"Neelakantan, Arvind\" name=\"citation_author\"/>\n",
      "  <meta content=\"Shyam, Pranav\" name=\"citation_author\"/>\n",
      "  <meta content=\"Sastry, Girish\" name=\"citation_author\"/>\n",
      "  <meta content=\"Askell, Amanda\" name=\"citation_author\"/>\n",
      "  <meta content=\"Agarwal, Sandhini\" name=\"citation_author\"/>\n",
      "  <meta content=\"Herbert-Voss, Ariel\" name=\"citation_author\"/>\n",
      "  <meta content=\"Krueger, Gretchen\" name=\"citation_author\"/>\n",
      "  <meta content=\"Henighan, Tom\" name=\"citation_author\"/>\n",
      "  <meta content=\"Child, Rewon\" name=\"citation_author\"/>\n",
      "  <meta content=\"Ramesh, Aditya\" name=\"citation_author\"/>\n",
      "  <meta content=\"Ziegler, Daniel M.\" name=\"citation_author\"/>\n",
      "  <meta content=\"Wu, Jeffrey\" name=\"citation_author\"/>\n",
      "  <meta content=\"Winter, Clemens\" name=\"citation_author\"/>\n",
      "  <meta content=\"Hesse, Christopher\" name=\"citation_author\"/>\n",
      "  <meta content=\"Chen, Mark\" name=\"citation_author\"/>\n",
      "  <meta content=\"Sigler, Eric\" name=\"citation_author\"/>\n",
      "  <meta content=\"Litwin, Mateusz\" name=\"citation_author\"/>\n",
      "  <meta content=\"Gray, Scott\" name=\"citation_author\"/>\n",
      "  <meta content=\"Chess, Benjamin\" name=\"citation_author\"/>\n",
      "  <meta content=\"Clark, Jack\" name=\"citation_author\"/>\n",
      "  <meta content=\"Berner, Christopher\" name=\"citation_author\"/>\n",
      "  <meta content=\"McCandlish, Sam\" name=\"citation_author\"/>\n",
      "  <meta content=\"Radford, Alec\" name=\"citation_author\"/>\n",
      "  <meta content=\"Sutskever, Ilya\" name=\"citation_author\"/>\n",
      "  <meta content=\"Amodei, Dario\" name=\"citation_author\"/>\n",
      "  <meta content=\"2020/05/28\" name=\"citation_date\"/>\n",
      "  <meta content=\"2020/07/22\" name=\"citation_online_date\"/>\n",
      "  <meta content=\"https://arxiv.org/pdf/2005.14165\" name=\"citation_pdf_url\"/>\n",
      "  <meta content=\"2005.14165\" name=\"citation_arxiv_id\"/>\n",
      "  <meta content=\"@arxiv\" name=\"twitter:site\"/>\n",
      "  <meta content=\"Language Models are Few-Shot Learners\" property=\"twitter:title\"/>\n",
      "  <meta content=\"Recent work has demonstrated substantial gains on many NLP tasks and\n",
      "benchmarks by pre-training on a large corpus of text followed by fine-tuning on\n",
      "a specific task. While typically task-agnostic...\" property=\"twitter:description\"/>\n",
      "  <meta content=\"arXiv.org\" property=\"og:site_name\"/>\n",
      "  <meta content=\"Language Models are Few-Shot Learners\" property=\"og:title\"/>\n",
      "  <meta content=\"https://arxiv.org/abs/2005.14165v4\" property=\"og:url\"/>\n",
      "  <meta content=\"Recent work has demonstrated substantial gains on many NLP tasks and\n",
      "benchmarks by pre-training on a large corpus of text followed by fine-tuning on\n",
      "a specific task. While typically task-agnostic in architecture, this method\n",
      "still requires task-specific fine-tuning datasets of thousands or tens of\n",
      "thousands of examples. By contrast, humans can generally perform a new language\n",
      "task from only a few examples or from simple instructions - something which\n",
      "current NLP systems still largely struggle to do. Here we show that scaling up\n",
      "language models greatly improves task-agnostic, few-shot performance, sometimes\n",
      "even reaching competitiveness with prior state-of-the-art fine-tuning\n",
      "approaches. Specifically, we train GPT-3, an autoregressive language model with\n",
      "175 billion parameters, 10x more than any previous non-sparse language model,\n",
      "and test its performance in the few-shot setting. For all tasks, GPT-3 is\n",
      "applied without any gradient updates or fine-tuning, with tasks and few-shot\n",
      "demonstrations specified purely via text interaction with the model. GPT-3\n",
      "achieves strong performance on many NLP datasets, including translation,\n",
      "question-answering, and cloze tasks, as well as several tasks that require\n",
      "on-the-fly reasoning or domain adaptation, such as unscrambling words, using a\n",
      "novel word in a sentence, or performing 3-digit arithmetic. At the same time,\n",
      "we also identify some datasets where GPT-3's few-shot learning still struggles,\n",
      "as well as some datasets where GPT-3 faces methodological issues related to\n",
      "training on large web corpora. Finally, we find that GPT-3 can generate samples\n",
      "of news articles which human evaluators have difficulty distinguishing from\n",
      "articles written by humans. We discuss broader societal impacts of this finding\n",
      "and of GPT-3 in general.\" property=\"og:description\"/>\n",
      " </head>\n",
      " <body class=\"with-cu-identity\">\n",
      "  <aside class=\"slider-wrapper\" style=\"display:none\">\n",
      "   <a class=\"close-slider\" href=\"#\">\n",
      "    <img alt=\"close this message\" src=\"https://static.arxiv.org/static/browse/0.3.2.5/images/icons/close-slider.png\"/>\n",
      "   </a>\n",
      "   <div class=\"copy-donation\">\n",
      "    <h1>\n",
      "     Donate to arXiv\n",
      "    </h1>\n",
      "    <p>\n",
      "     Please join the\n",
      "     <a href=\"https://simonsfoundation.org\">\n",
      "      Simons Foundation\n",
      "     </a>\n",
      "     and our\n",
      "      generous\n",
      "     <a href=\"https://arxiv.org/about/ourmembers\">\n",
      "      member organizations\n",
      "     </a>\n",
      "     in supporting arXiv during our giving campaign September 23-27. 100% of your contribution will fund\n",
      "      improvements and new initiatives to benefit arXiv's global scientific community.\n",
      "    </p>\n",
      "   </div>\n",
      "   <div class=\"amount-donation\">\n",
      "    <div class=\"wrapper\">\n",
      "     <div class=\"donate-cta\">\n",
      "      <a class=\"banner_link\" href=\"https://bit.ly/arXivDONATE1\">\n",
      "       <b>\n",
      "        DONATE\n",
      "       </b>\n",
      "      </a>\n",
      "      <p>\n",
      "       [secure site, no need to create account]\n",
      "      </p>\n",
      "     </div>\n",
      "    </div>\n",
      "   </div>\n",
      "  </aside>\n",
      "  <div class=\"flex-wrap-footer\">\n",
      "   <header>\n",
      "    <a class=\"is-sr-only\" href=\"#content\">\n",
      "     Skip to main content\n",
      "    </a>\n",
      "    <!-- start desktop header -->\n",
      "    <div class=\"columns is-vcentered is-hidden-mobile\" id=\"cu-identity\">\n",
      "     <div class=\"column\" id=\"cu-logo\">\n",
      "      <a href=\"https://www.cornell.edu/\">\n",
      "       <img alt=\"Cornell University\" src=\"https://static.arxiv.org/static/browse/0.3.2.5/images/icons/cu/cornell-reduced-white-SMALL.svg\"/>\n",
      "      </a>\n",
      "     </div>\n",
      "     <!-- timeboxed column -->\n",
      "     <!-- /end timeboxed column -->\n",
      "     <div class=\"column\" id=\"support-ack\">\n",
      "      <a href=\"https://confluence.cornell.edu/x/ALlRF\">\n",
      "       We gratefully acknowledge support from\n",
      "       <br/>\n",
      "       the Simons Foundation and member institutions.\n",
      "      </a>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"is-hidden-mobile\" id=\"header\">\n",
      "     <a aria-hidden=\"true\" href=\"{url_path('ignore_me')}\">\n",
      "     </a>\n",
      "     <div class=\"header-breadcrumbs is-hidden-mobile\">\n",
      "      <a href=\"/\">\n",
      "       arXiv.org\n",
      "      </a>\n",
      "      &gt;\n",
      "      <a href=\"/list/cs/recent\">\n",
      "       cs\n",
      "      </a>\n",
      "      &gt; arXiv:2005.14165\n",
      "     </div>\n",
      "     <div class=\"search-block level-right\">\n",
      "      <form action=\"https://arxiv.org/search\" class=\"level-item mini-search\" method=\"GET\">\n",
      "       <div class=\"field has-addons\">\n",
      "        <div class=\"control\">\n",
      "         <input aria-label=\"Search term or terms\" class=\"input is-small\" name=\"query\" placeholder=\"Search...\" type=\"text\"/>\n",
      "         <p class=\"help\">\n",
      "          <a href=\"https://arxiv.org/help\">\n",
      "           Help\n",
      "          </a>\n",
      "          |\n",
      "          <a href=\"https://arxiv.org/search/advanced\">\n",
      "           Advanced Search\n",
      "          </a>\n",
      "         </p>\n",
      "        </div>\n",
      "        <div class=\"control\">\n",
      "         <div class=\"select is-small\">\n",
      "          <select aria-label=\"Field to search\" name=\"searchtype\">\n",
      "           <option selected=\"selected\" value=\"all\">\n",
      "            All fields\n",
      "           </option>\n",
      "           <option value=\"title\">\n",
      "            Title\n",
      "           </option>\n",
      "           <option value=\"author\">\n",
      "            Author\n",
      "           </option>\n",
      "           <option value=\"abstract\">\n",
      "            Abstract\n",
      "           </option>\n",
      "           <option value=\"comments\">\n",
      "            Comments\n",
      "           </option>\n",
      "           <option value=\"journal_ref\">\n",
      "            Journal reference\n",
      "           </option>\n",
      "           <option value=\"acm_class\">\n",
      "            ACM classification\n",
      "           </option>\n",
      "           <option value=\"msc_class\">\n",
      "            MSC classification\n",
      "           </option>\n",
      "           <option value=\"report_num\">\n",
      "            Report number\n",
      "           </option>\n",
      "           <option value=\"paper_id\">\n",
      "            arXiv identifier\n",
      "           </option>\n",
      "           <option value=\"doi\">\n",
      "            DOI\n",
      "           </option>\n",
      "           <option value=\"orcid\">\n",
      "            ORCID\n",
      "           </option>\n",
      "           <option value=\"author_id\">\n",
      "            arXiv author ID\n",
      "           </option>\n",
      "           <option value=\"help\">\n",
      "            Help pages\n",
      "           </option>\n",
      "           <option value=\"full_text\">\n",
      "            Full text\n",
      "           </option>\n",
      "          </select>\n",
      "         </div>\n",
      "        </div>\n",
      "        <input name=\"source\" type=\"hidden\" value=\"header\"/>\n",
      "        <button class=\"button is-small is-cul-darker\">\n",
      "         Search\n",
      "        </button>\n",
      "       </div>\n",
      "      </form>\n",
      "     </div>\n",
      "    </div>\n",
      "    <!-- /end desktop header -->\n",
      "    <div class=\"mobile-header\">\n",
      "     <div class=\"columns is-mobile\">\n",
      "      <div class=\"column logo-arxiv\">\n",
      "       <a href=\"https://arxiv.org/\">\n",
      "        <img alt=\"arXiv\" src=\"https://static.arxiv.org/static/browse/0.3.2.5/images/arxiv-logo.png\"/>\n",
      "       </a>\n",
      "      </div>\n",
      "      <div class=\"column logo-cornell\">\n",
      "       <a href=\"https://www.cornell.edu/\">\n",
      "        <picture>\n",
      "         <source media=\"(min-width: 501px)\" sizes=\"400w\" srcset=\"https://static.arxiv.org/static/browse/0.3.2.5/images/icons/cu/cornell-reduced-white-SMALL.svg  400w\"/>\n",
      "         <source srcset=\"https://static.arxiv.org/static/browse/0.3.2.5/images/icons/cu/cornell_seal_simple_black.svg 2x\"/>\n",
      "         <img alt=\"Cornell University Logo\" src=\"https://static.arxiv.org/static/browse/0.3.2.5/images/icons/cu/cornell-reduced-white-SMALL.svg\"/>\n",
      "        </picture>\n",
      "       </a>\n",
      "      </div>\n",
      "      <div class=\"column nav\" id=\"toggle-container\" role=\"menubar\">\n",
      "       <button class=\"toggle-control\">\n",
      "        <svg class=\"icon filter-white\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "         <title>\n",
      "          open search\n",
      "         </title>\n",
      "         <path d=\"M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z\">\n",
      "         </path>\n",
      "        </svg>\n",
      "       </button>\n",
      "       <div class=\"mobile-toggle-block toggle-target\">\n",
      "        <form action=\"https://arxiv.org/search\" class=\"mobile-search-form\" method=\"GET\">\n",
      "         <div class=\"field has-addons\">\n",
      "          <input aria-label=\"Search term or terms\" class=\"input\" name=\"query\" placeholder=\"Search...\" type=\"text\"/>\n",
      "          <input name=\"source\" type=\"hidden\" value=\"header\"/>\n",
      "          <input name=\"searchtype\" type=\"hidden\" value=\"all\"/>\n",
      "          <button class=\"button\">\n",
      "           GO\n",
      "          </button>\n",
      "         </div>\n",
      "        </form>\n",
      "       </div>\n",
      "       <button class=\"toggle-control\">\n",
      "        <svg class=\"icon filter-white\" role=\"menu\" viewbox=\"0 0 448 512\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "         <title>\n",
      "          open navigation menu\n",
      "         </title>\n",
      "         <path d=\"M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z\">\n",
      "         </path>\n",
      "        </svg>\n",
      "       </button>\n",
      "       <div class=\"mobile-toggle-block toggle-target\">\n",
      "        <nav aria-labelledby=\"mobilemenulabel\" class=\"mobile-menu\">\n",
      "         <h2 id=\"mobilemenulabel\">\n",
      "          quick links\n",
      "         </h2>\n",
      "         <ul>\n",
      "          <li>\n",
      "           <a href=\"https://arxiv.org/login\">\n",
      "            Login\n",
      "           </a>\n",
      "          </li>\n",
      "          <li>\n",
      "           <a href=\"https://arxiv.org/help\">\n",
      "            Help Pages\n",
      "           </a>\n",
      "          </li>\n",
      "          <li>\n",
      "           <a href=\"https://arxiv.org/about\">\n",
      "            About\n",
      "           </a>\n",
      "          </li>\n",
      "         </ul>\n",
      "        </nav>\n",
      "       </div>\n",
      "      </div>\n",
      "     </div>\n",
      "    </div>\n",
      "    <!-- /end mobile-header -->\n",
      "   </header>\n",
      "   <main>\n",
      "    <div id=\"content\">\n",
      "     <!--\n",
      "rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
      "         xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n",
      "         xmlns:trackback=\"http://madskills.com/public/xml/rss/module/trackback/\">\n",
      "    <rdf:Description\n",
      "        rdf:about=\"/abs/2005.14165\"\n",
      "        dc:identifier=\"/abs/2005.14165\"\n",
      "        dc:title=\"Language Models are Few-Shot Learners\"\n",
      "        trackback:ping=\"/trackback/2005.14165\" />\n",
      "    </rdf:RDF>\n",
      "-->\n",
      "     <div id=\"abs-outer\">\n",
      "      <div class=\"leftcolumn\">\n",
      "       <div class=\"subheader\">\n",
      "        <h1>\n",
      "         Computer Science &gt; Computation and Language\n",
      "        </h1>\n",
      "       </div>\n",
      "       <div class=\"header-breadcrumbs-mobile\">\n",
      "        <strong>\n",
      "         arXiv:2005.14165\n",
      "        </strong>\n",
      "        (cs)\n",
      "       </div>\n",
      "       <link href=\"https://static.arxiv.org/static/base/0.16.8/css/abs.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "       <div id=\"content-inner\">\n",
      "        <div id=\"abs\">\n",
      "         <div class=\"dateline\">\n",
      "          [Submitted on 28 May 2020 (\n",
      "          <a href=\"https://arxiv.org/abs/2005.14165v1\">\n",
      "           v1\n",
      "          </a>\n",
      "          ), last revised 22 Jul 2020 (this version, v4)]\n",
      "         </div>\n",
      "         <h1 class=\"title mathjax\">\n",
      "          <span class=\"descriptor\">\n",
      "           Title:\n",
      "          </span>\n",
      "          Language Models are Few-Shot Learners\n",
      "         </h1>\n",
      "         <div class=\"authors\">\n",
      "          <span class=\"descriptor\">\n",
      "           Authors:\n",
      "          </span>\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Brown%2C+T+B\">\n",
      "           Tom B. Brown\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Mann%2C+B\">\n",
      "           Benjamin Mann\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ryder%2C+N\">\n",
      "           Nick Ryder\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Subbiah%2C+M\">\n",
      "           Melanie Subbiah\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kaplan%2C+J\">\n",
      "           Jared Kaplan\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Dhariwal%2C+P\">\n",
      "           Prafulla Dhariwal\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Neelakantan%2C+A\">\n",
      "           Arvind Neelakantan\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shyam%2C+P\">\n",
      "           Pranav Shyam\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sastry%2C+G\">\n",
      "           Girish Sastry\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Askell%2C+A\">\n",
      "           Amanda Askell\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Agarwal%2C+S\">\n",
      "           Sandhini Agarwal\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Herbert-Voss%2C+A\">\n",
      "           Ariel Herbert-Voss\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Krueger%2C+G\">\n",
      "           Gretchen Krueger\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Henighan%2C+T\">\n",
      "           Tom Henighan\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Child%2C+R\">\n",
      "           Rewon Child\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ramesh%2C+A\">\n",
      "           Aditya Ramesh\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Ziegler%2C+D+M\">\n",
      "           Daniel M. Ziegler\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wu%2C+J\">\n",
      "           Jeffrey Wu\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Winter%2C+C\">\n",
      "           Clemens Winter\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Hesse%2C+C\">\n",
      "           Christopher Hesse\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M\">\n",
      "           Mark Chen\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sigler%2C+E\">\n",
      "           Eric Sigler\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Litwin%2C+M\">\n",
      "           Mateusz Litwin\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gray%2C+S\">\n",
      "           Scott Gray\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chess%2C+B\">\n",
      "           Benjamin Chess\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Clark%2C+J\">\n",
      "           Jack Clark\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Berner%2C+C\">\n",
      "           Christopher Berner\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=McCandlish%2C+S\">\n",
      "           Sam McCandlish\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Radford%2C+A\">\n",
      "           Alec Radford\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sutskever%2C+I\">\n",
      "           Ilya Sutskever\n",
      "          </a>\n",
      "          ,\n",
      "          <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Amodei%2C+D\">\n",
      "           Dario Amodei\n",
      "          </a>\n",
      "         </div>\n",
      "         <a class=\"mobile-submission-download\" href=\"/pdf/2005.14165\">\n",
      "          Download PDF\n",
      "         </a>\n",
      "         <blockquote class=\"abstract mathjax\">\n",
      "          <span class=\"descriptor\">\n",
      "           Abstract:\n",
      "          </span>\n",
      "          Recent work has demonstrated substantial gains on many NLP tasks and\n",
      "benchmarks by pre-training on a large corpus of text followed by fine-tuning on\n",
      "a specific task. While typically task-agnostic in architecture, this method\n",
      "still requires task-specific fine-tuning datasets of thousands or tens of\n",
      "thousands of examples. By contrast, humans can generally perform a new language\n",
      "task from only a few examples or from simple instructions - something which\n",
      "current NLP systems still largely struggle to do. Here we show that scaling up\n",
      "language models greatly improves task-agnostic, few-shot performance, sometimes\n",
      "even reaching competitiveness with prior state-of-the-art fine-tuning\n",
      "approaches. Specifically, we train GPT-3, an autoregressive language model with\n",
      "175 billion parameters, 10x more than any previous non-sparse language model,\n",
      "and test its performance in the few-shot setting. For all tasks, GPT-3 is\n",
      "applied without any gradient updates or fine-tuning, with tasks and few-shot\n",
      "demonstrations specified purely via text interaction with the model. GPT-3\n",
      "achieves strong performance on many NLP datasets, including translation,\n",
      "question-answering, and cloze tasks, as well as several tasks that require\n",
      "on-the-fly reasoning or domain adaptation, such as unscrambling words, using a\n",
      "novel word in a sentence, or performing 3-digit arithmetic. At the same time,\n",
      "we also identify some datasets where GPT-3's few-shot learning still struggles,\n",
      "as well as some datasets where GPT-3 faces methodological issues related to\n",
      "training on large web corpora. Finally, we find that GPT-3 can generate samples\n",
      "of news articles which human evaluators have difficulty distinguishing from\n",
      "articles written by humans. We discuss broader societal impacts of this finding\n",
      "and of GPT-3 in general.\n",
      "         </blockquote>\n",
      "         <!--CONTEXT-->\n",
      "         <div class=\"metatable\">\n",
      "          <table summary=\"Additional metadata\">\n",
      "           <tr>\n",
      "            <td class=\"tablecell label\">\n",
      "             Comments:\n",
      "            </td>\n",
      "            <td class=\"tablecell comments mathjax\">\n",
      "             40+32 pages\n",
      "            </td>\n",
      "           </tr>\n",
      "           <tr>\n",
      "            <td class=\"tablecell label\">\n",
      "             Subjects:\n",
      "            </td>\n",
      "            <td class=\"tablecell subjects\">\n",
      "             <span class=\"primary-subject\">\n",
      "              Computation and Language (cs.CL)\n",
      "             </span>\n",
      "            </td>\n",
      "           </tr>\n",
      "           <tr>\n",
      "            <td class=\"tablecell label\">\n",
      "             Cite as:\n",
      "            </td>\n",
      "            <td class=\"tablecell arxivid\">\n",
      "             <span class=\"arxivid\">\n",
      "              <a href=\"https://arxiv.org/abs/2005.14165\">\n",
      "               arXiv:2005.14165\n",
      "              </a>\n",
      "              [cs.CL]\n",
      "             </span>\n",
      "            </td>\n",
      "           </tr>\n",
      "           <tr>\n",
      "            <td class=\"tablecell label\">\n",
      "            </td>\n",
      "            <td class=\"tablecell arxividv\">\n",
      "             (or\n",
      "             <span class=\"arxivid\">\n",
      "              <a href=\"https://arxiv.org/abs/2005.14165v4\">\n",
      "               arXiv:2005.14165v4\n",
      "              </a>\n",
      "              [cs.CL]\n",
      "             </span>\n",
      "             for this version)\n",
      "            </td>\n",
      "           </tr>\n",
      "          </table>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div class=\"submission-history\">\n",
      "        <h2>\n",
      "         Submission history\n",
      "        </h2>\n",
      "        From: Tom B Brown [\n",
      "        <a href=\"/show-email/b5cb66e9/2005.14165\">\n",
      "         view email\n",
      "        </a>\n",
      "        ]\n",
      "        <br/>\n",
      "        <strong>\n",
      "         <a href=\"/abs/2005.14165v1\">\n",
      "          [v1]\n",
      "         </a>\n",
      "        </strong>\n",
      "        Thu, 28 May 2020 17:29:03 UTC (6,995 KB)\n",
      "        <br/>\n",
      "        <strong>\n",
      "         <a href=\"/abs/2005.14165v2\">\n",
      "          [v2]\n",
      "         </a>\n",
      "        </strong>\n",
      "        Mon, 1 Jun 2020 17:08:53 UTC (6,997 KB)\n",
      "        <br/>\n",
      "        <strong>\n",
      "         <a href=\"/abs/2005.14165v3\">\n",
      "          [v3]\n",
      "         </a>\n",
      "        </strong>\n",
      "        Fri, 5 Jun 2020 02:52:35 UTC (6,998 KB)\n",
      "        <br/>\n",
      "        <strong>\n",
      "         [v4]\n",
      "        </strong>\n",
      "        Wed, 22 Jul 2020 19:47:17 UTC (6,998 KB)\n",
      "        <br/>\n",
      "       </div>\n",
      "      </div>\n",
      "      <!--end leftcolumn-->\n",
      "      <div class=\"extra-services\">\n",
      "       <div class=\"full-text\">\n",
      "        <a name=\"other\">\n",
      "        </a>\n",
      "        <span class=\"descriptor\">\n",
      "         Full-text links:\n",
      "        </span>\n",
      "        <h2>\n",
      "         Download:\n",
      "        </h2>\n",
      "        <ul>\n",
      "         <li>\n",
      "          <a accesskey=\"f\" class=\"abs-button download-pdf\" href=\"/pdf/2005.14165\">\n",
      "           PDF\n",
      "          </a>\n",
      "         </li>\n",
      "         <li>\n",
      "          <a class=\"abs-button download-format\" href=\"/format/2005.14165\">\n",
      "           Other formats\n",
      "          </a>\n",
      "         </li>\n",
      "        </ul>\n",
      "        <div class=\"abs-license\">\n",
      "         (\n",
      "         <a href=\"http://arxiv.org/licenses/nonexclusive-distrib/1.0/\" title=\"Rights to this article\">\n",
      "          license\n",
      "         </a>\n",
      "         )\n",
      "        </div>\n",
      "       </div>\n",
      "       <!--end full-text-->\n",
      "       <div class=\"browse\">\n",
      "        Current browse context:\n",
      "        <div class=\"current\">\n",
      "         cs.CL\n",
      "        </div>\n",
      "        <div class=\"prevnext\">\n",
      "         <span class=\"arrow\">\n",
      "          <a accesskey=\"p\" class=\"abs-button prev-url\" href=\"/prevnext?id=2005.14165&amp;function=prev&amp;context=cs.CL\" title=\"previous in cs.CL (accesskey p)\">\n",
      "           &lt; prev\n",
      "          </a>\n",
      "         </span>\n",
      "         <span class=\"is-hidden-mobile\">\n",
      "          |\n",
      "         </span>\n",
      "         <span class=\"arrow\">\n",
      "          <a accesskey=\"n\" class=\"abs-button next-url\" href=\"/prevnext?id=2005.14165&amp;function=next&amp;context=cs.CL\" title=\"next in cs.CL (accesskey n)\">\n",
      "           next &gt;\n",
      "          </a>\n",
      "         </span>\n",
      "         <br/>\n",
      "        </div>\n",
      "        <div class=\"list\">\n",
      "         <a class=\"abs-button abs-button-grey abs-button-small context-new\" href=\"/list/cs.CL/new\">\n",
      "          new\n",
      "         </a>\n",
      "         <span class=\"is-hidden-mobile\">\n",
      "          |\n",
      "         </span>\n",
      "         <a class=\"abs-button abs-button-grey abs-button-small context-recent\" href=\"/list/cs.CL/recent\">\n",
      "          recent\n",
      "         </a>\n",
      "         <span class=\"is-hidden-mobile\">\n",
      "          |\n",
      "         </span>\n",
      "         <a class=\"abs-button abs-button-grey abs-button-small context-id\" href=\"/list/cs.CL/2005\">\n",
      "          2005\n",
      "         </a>\n",
      "        </div>\n",
      "        <div class=\"abs-switch-cat\">\n",
      "         Change to browse by:\n",
      "         <div class=\"switch context-change\">\n",
      "          <a href=\"/abs/2005.14165?context=cs\">\n",
      "           cs\n",
      "          </a>\n",
      "          <br class=\"is-hidden-mobile\"/>\n",
      "         </div>\n",
      "        </div>\n",
      "       </div>\n",
      "       <div class=\"extra-ref-cite\">\n",
      "        <h3>\n",
      "         References &amp; Citations\n",
      "        </h3>\n",
      "        <ul>\n",
      "         <li>\n",
      "          <a class=\"abs-button abs-button-small cite-ads\" href=\"https://ui.adsabs.harvard.edu/abs/arXiv:2005.14165\">\n",
      "           NASA ADS\n",
      "          </a>\n",
      "         </li>\n",
      "         <li>\n",
      "          <a class=\"abs-button abs-button-small cite-google-scholar\" href=\"https://scholar.google.com/scholar?q=Language%20Models%20are%20Few-Shot%20Learners.%20arXiv%202020\" rel=\"noopener\" target=\"_blank\">\n",
      "           Google Scholar\n",
      "          </a>\n",
      "         </li>\n",
      "         <li>\n",
      "          <a class=\"abs-button abs-button-small cite-semantic-scholar\" href=\"https://api.semanticscholar.org/arXiv:2005.14165\" rel=\"noopener\" target=\"_blank\">\n",
      "           Semantic Scholar\n",
      "          </a>\n",
      "         </li>\n",
      "        </ul>\n",
      "        <div style=\"clear:both;\">\n",
      "        </div>\n",
      "       </div>\n",
      "       <div class=\"extra-general\">\n",
      "        <div class=\"what-is-this\">\n",
      "         <h3>\n",
      "          <a class=\"abs-button abs-button-grey abs-button-small trackback-link\" href=\"/tb/2005.14165\">\n",
      "           23 blog links\n",
      "          </a>\n",
      "         </h3>\n",
      "         (\n",
      "         <a class=\"trackback-help\" href=\"https://arxiv.org/help/trackback\">\n",
      "          what is this?\n",
      "         </a>\n",
      "         )\n",
      "        </div>\n",
      "       </div>\n",
      "       <div class=\"bookmarks\">\n",
      "        <div>\n",
      "         <h3>\n",
      "          Bookmark\n",
      "         </h3>\n",
      "        </div>\n",
      "        <a class=\"abs-button abs-button-grey abs-button-small\" href=\"https://arxiv.org/ct?url=http%3A%2F%2Fwww.bibsonomy.org%2FBibtexHandler%3FrequTask%3Dupload%26url%3Dhttps%3A%2F%2Farxiv.org%2Fabs%2F2005.14165%26description%3DLanguage+Models+are+Few-Shot+Learners&amp;v=b626719b\" title=\"Bookmark on BibSonomy\">\n",
      "         <img alt=\"BibSonomy logo\" src=\"https://static.arxiv.org/static/browse/0.3.2.5/images/icons/social/bibsonomy.png\"/>\n",
      "        </a>\n",
      "        <a class=\"abs-button abs-button-grey abs-button-small\" href=\"https://arxiv.org/ct?url=https%3A%2F%2Fwww.mendeley.com%2Fimport%2F%3Furl%3Dhttps%3A%2F%2Farxiv.org%2Fabs%2F2005.14165&amp;v=20f396a5\" title=\"Bookmark on Mendeley\">\n",
      "         <img alt=\"Mendeley logo\" src=\"https://static.arxiv.org/static/browse/0.3.2.5/images/icons/social/mendeley.png\"/>\n",
      "        </a>\n",
      "        <a class=\"abs-button abs-button-grey abs-button-small\" href=\"https://arxiv.org/ct?url=https%3A%2F%2Freddit.com%2Fsubmit%3Furl%3Dhttps%3A%2F%2Farxiv.org%2Fabs%2F2005.14165%26title%3DLanguage+Models+are+Few-Shot+Learners&amp;v=56e15329\" title=\"Bookmark on Reddit\">\n",
      "         <img alt=\"Reddit logo\" src=\"https://static.arxiv.org/static/browse/0.3.2.5/images/icons/social/reddit.png\"/>\n",
      "        </a>\n",
      "        <a class=\"abs-button abs-button-grey abs-button-small\" href=\"https://arxiv.org/ct?url=http%3A%2F%2Fsciencewise.info%2Fbookmarks%2Fadd%3Furl%3Dhttps%3A%2F%2Farxiv.org%2Fabs%2F2005.14165&amp;v=3501b1c3\" title=\"Bookmark on ScienceWISE\">\n",
      "         <img alt=\"ScienceWISE logo\" src=\"https://static.arxiv.org/static/browse/0.3.2.5/images/icons/social/sciencewise.png\"/>\n",
      "        </a>\n",
      "       </div>\n",
      "      </div>\n",
      "      <!--end extra-services-->\n",
      "      <div class=\"endorsers\">\n",
      "       <a class=\"endorser-who\" href=\"/auth/show-endorsers/2005.14165\">\n",
      "        Which authors of this paper are endorsers?\n",
      "       </a>\n",
      "       |\n",
      "       <a href=\"javascript:setMathjaxCookie()\" id=\"mathjax_toggle\">\n",
      "        Disable MathJax\n",
      "       </a>\n",
      "       (\n",
      "       <a href=\"https://arxiv.org/help/mathjax\">\n",
      "        What is MathJax?\n",
      "       </a>\n",
      "       )\n",
      "       <span class=\"help\" style=\"font-style: normal; float: right; margin-top: 0; margin-right: 1em;\">\n",
      "        <a href=\"https://github.com/arXiv/arxiv-browse/releases/tag/0.3.2.5\">\n",
      "         Browse v0.3.2.5 released 2020-07-27\n",
      "        </a>\n",
      "        <button class=\"button is-small\" id=\"feedback-button\">\n",
      "         Feedback?\n",
      "        </button>\n",
      "       </span>\n",
      "      </div>\n",
      "      <script language=\"javascript\" type=\"text/javascript\">\n",
      "       mathjaxToggle();\n",
      "      </script>\n",
      "      <script defer=\"\" src=\"/bibex/bibex.js?20181010\" type=\"text/javascript\">\n",
      "      </script>\n",
      "     </div>\n",
      "    </div>\n",
      "   </main>\n",
      "   <footer style=\"clear: both;\">\n",
      "    <div aria-label=\"Secondary\" class=\"columns is-desktop\" role=\"navigation\" style=\"margin: -0.75em -0.75em 0.75em -0.75em\">\n",
      "     <!-- Macro-Column 1 -->\n",
      "     <div class=\"column\" style=\"padding: 0;\">\n",
      "      <div class=\"columns\">\n",
      "       <div class=\"column\">\n",
      "        <ul style=\"list-style: none; line-height: 2;\">\n",
      "         <li>\n",
      "          <a href=\"https://arxiv.org/about\">\n",
      "           About\n",
      "          </a>\n",
      "         </li>\n",
      "         <li>\n",
      "          <a href=\"https://arxiv.org/help\">\n",
      "           Help\n",
      "          </a>\n",
      "         </li>\n",
      "        </ul>\n",
      "       </div>\n",
      "       <div class=\"column\">\n",
      "        <ul style=\"list-style: none; line-height: 2;\">\n",
      "         <li>\n",
      "          <svg class=\"icon filter-black\" role=\"presentation\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "           <title>\n",
      "            contact arXiv\n",
      "           </title>\n",
      "           <desc>\n",
      "            Click here to contact arXiv\n",
      "           </desc>\n",
      "           <path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\">\n",
      "           </path>\n",
      "          </svg>\n",
      "          <a href=\"https://arxiv.org/help/contact\">\n",
      "           Contact\n",
      "          </a>\n",
      "         </li>\n",
      "         <li>\n",
      "          <svg class=\"icon filter-black\" role=\"presentation\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "           <title>\n",
      "            subscribe to arXiv mailings\n",
      "           </title>\n",
      "           <desc>\n",
      "            Click here to subscribe\n",
      "           </desc>\n",
      "           <path d=\"M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z\">\n",
      "           </path>\n",
      "          </svg>\n",
      "          <a href=\"https://arxiv.org/help/subscribe\">\n",
      "           Subscribe\n",
      "          </a>\n",
      "         </li>\n",
      "        </ul>\n",
      "       </div>\n",
      "      </div>\n",
      "     </div>\n",
      "     <!-- End Macro-Column 1 -->\n",
      "     <!-- Macro-Column 2 -->\n",
      "     <div class=\"column\" style=\"padding: 0;\">\n",
      "      <div class=\"columns\">\n",
      "       <div class=\"column\">\n",
      "        <ul style=\"list-style: none; line-height: 2;\">\n",
      "         <li>\n",
      "          <a href=\"https://arxiv.org/help/license\">\n",
      "           Copyright\n",
      "          </a>\n",
      "         </li>\n",
      "         <li>\n",
      "          <a href=\"https://arxiv.org/help/policies/privacy_policy\">\n",
      "           Privacy Policy\n",
      "          </a>\n",
      "         </li>\n",
      "        </ul>\n",
      "       </div>\n",
      "       <div class=\"column sorry-app-links\">\n",
      "        <ul style=\"list-style: none; line-height: 2;\">\n",
      "         <li>\n",
      "          <a href=\"https://arxiv.org/help/web_accessibility\">\n",
      "           Web Accessibility Assistance\n",
      "          </a>\n",
      "         </li>\n",
      "         <li>\n",
      "          <p class=\"help\">\n",
      "           <a class=\"a11y-main-link\" href=\"https://status.arxiv.org\" target=\"_blank\">\n",
      "            arXiv Operational Status\n",
      "            <svg class=\"icon filter-dark_grey\" role=\"presentation\" viewbox=\"0 0 256 512\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "             <path d=\"M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z\">\n",
      "             </path>\n",
      "            </svg>\n",
      "           </a>\n",
      "           <br/>\n",
      "           Get status notifications via\n",
      "           <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/email/new\" target=\"_blank\">\n",
      "            <svg class=\"icon filter-black\" role=\"presentation\" viewbox=\"0 0 512 512\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "             <path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\">\n",
      "             </path>\n",
      "            </svg>\n",
      "            email\n",
      "           </a>\n",
      "           or\n",
      "           <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/slack/new\" target=\"_blank\">\n",
      "            <svg class=\"icon filter-black\" role=\"presentation\" viewbox=\"0 0 448 512\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "             <path d=\"M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z\">\n",
      "             </path>\n",
      "            </svg>\n",
      "            slack\n",
      "           </a>\n",
      "          </p>\n",
      "         </li>\n",
      "        </ul>\n",
      "       </div>\n",
      "      </div>\n",
      "     </div>\n",
      "     <!-- end MetaColumn 2 -->\n",
      "     <!-- End Macro-Column 2 -->\n",
      "    </div>\n",
      "   </footer>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(requests.get(\"https://arxiv.org/abs/2005.14165\").text, 'lxml')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors:Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, Dario Amodei\n"
     ]
    }
   ],
   "source": [
    "authros = soup.find('div', class_='authors')\n",
    "print(authros.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://arxiv.org/search/cs?searchtype=author&query=Brown%2C+T+B'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_link = authors.a['href']\n",
    "authors_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/search/cs?searchtype=author&query=Brown%2C+T+B\n"
     ]
    }
   ],
   "source": [
    "for authors_link in soup.find_all('div', class_='authors'):\n",
    "    print(authors_link.a['href'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstract:  Recent work has demonstrated substantial gains on many NLP tasks and\n",
      "benchmarks by pre-training on a large corpus of text followed by fine-tuning on\n",
      "a specific task. While typically task-agnostic in architecture, this method\n",
      "still requires task-specific fine-tuning datasets of thousands or tens of\n",
      "thousands of examples. By contrast, humans can generally perform a new language\n",
      "task from only a few examples or from simple instructions - something which\n",
      "current NLP systems still largely struggle to do. Here we show that scaling up\n",
      "language models greatly improves task-agnostic, few-shot performance, sometimes\n",
      "even reaching competitiveness with prior state-of-the-art fine-tuning\n",
      "approaches. Specifically, we train GPT-3, an autoregressive language model with\n",
      "175 billion parameters, 10x more than any previous non-sparse language model,\n",
      "and test its performance in the few-shot setting. For all tasks, GPT-3 is\n",
      "applied without any gradient updates or fine-tuning, with tasks and few-shot\n",
      "demonstrations specified purely via text interaction with the model. GPT-3\n",
      "achieves strong performance on many NLP datasets, including translation,\n",
      "question-answering, and cloze tasks, as well as several tasks that require\n",
      "on-the-fly reasoning or domain adaptation, such as unscrambling words, using a\n",
      "novel word in a sentence, or performing 3-digit arithmetic. At the same time,\n",
      "we also identify some datasets where GPT-3's few-shot learning still struggles,\n",
      "as well as some datasets where GPT-3 faces methodological issues related to\n",
      "training on large web corpora. Finally, we find that GPT-3 can generate samples\n",
      "of news articles which human evaluators have difficulty distinguishing from\n",
      "articles written by humans. We discuss broader societal impacts of this finding\n",
      "and of GPT-3 in general.\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "abs = soup.find('blockquote', class_='abstract mathjax')\n",
    "print(abs.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \n",
      "  \n",
      "  \n",
      "    \n",
      "  \n",
      "  \n",
      "    \n",
      "    \n",
      "  \n",
      "\n",
      "  [Submitted on 28 May 2020 (v1), last revised 22 Jul 2020 (this version, v4)]\n"
     ]
    }
   ],
   "source": [
    "year = soup.find('div', class_ = 'dateline')\n",
    "print(year.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
